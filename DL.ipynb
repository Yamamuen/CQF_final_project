{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Classifier\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Dropout, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import talos\n",
    "from talos.utils import lr_normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import metrics\n",
    "import keras.backend as K\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking whether tensorflow is running on GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing final dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>mean_sent</th>\n",
       "      <th>STOCH_slowk</th>\n",
       "      <th>STOCH_slowd</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_hist</th>\n",
       "      <th>CCI_5</th>\n",
       "      <th>CCI_10</th>\n",
       "      <th>CCI_21</th>\n",
       "      <th>CCI_50</th>\n",
       "      <th>MOM_5</th>\n",
       "      <th>MOM_10</th>\n",
       "      <th>MOM_21</th>\n",
       "      <th>RSI_5</th>\n",
       "      <th>RSI_10</th>\n",
       "      <th>RSI_21</th>\n",
       "      <th>RSI_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011820</td>\n",
       "      <td>67.198744</td>\n",
       "      <td>57.422805</td>\n",
       "      <td>-12.540186</td>\n",
       "      <td>4.426599</td>\n",
       "      <td>-76.487357</td>\n",
       "      <td>-58.930944</td>\n",
       "      <td>-57.963081</td>\n",
       "      <td>-8.626979</td>\n",
       "      <td>-28.059998</td>\n",
       "      <td>-48.588989</td>\n",
       "      <td>-80.842987</td>\n",
       "      <td>30.94113</td>\n",
       "      <td>30.495281</td>\n",
       "      <td>36.523877</td>\n",
       "      <td>43.526454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>67.198744</td>\n",
       "      <td>57.422805</td>\n",
       "      <td>-12.540186</td>\n",
       "      <td>4.426599</td>\n",
       "      <td>-76.487357</td>\n",
       "      <td>-58.930944</td>\n",
       "      <td>-57.963081</td>\n",
       "      <td>-8.626979</td>\n",
       "      <td>-28.059998</td>\n",
       "      <td>-48.588989</td>\n",
       "      <td>-80.842987</td>\n",
       "      <td>30.94113</td>\n",
       "      <td>30.495281</td>\n",
       "      <td>36.523877</td>\n",
       "      <td>43.526454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009646</td>\n",
       "      <td>67.198744</td>\n",
       "      <td>57.422805</td>\n",
       "      <td>-12.540186</td>\n",
       "      <td>4.426599</td>\n",
       "      <td>-76.487357</td>\n",
       "      <td>-58.930944</td>\n",
       "      <td>-57.963081</td>\n",
       "      <td>-8.626979</td>\n",
       "      <td>-28.059998</td>\n",
       "      <td>-48.588989</td>\n",
       "      <td>-80.842987</td>\n",
       "      <td>30.94113</td>\n",
       "      <td>30.495281</td>\n",
       "      <td>36.523877</td>\n",
       "      <td>43.526454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  mean_sent  STOCH_slowk  STOCH_slowd       MACD  MACD_hist  \\\n",
       "Day                                                                             \n",
       "2015-01-01     0.0   0.011820    67.198744    57.422805 -12.540186   4.426599   \n",
       "2015-01-02     1.0   0.009464    67.198744    57.422805 -12.540186   4.426599   \n",
       "2015-01-03     0.0   0.009646    67.198744    57.422805 -12.540186   4.426599   \n",
       "\n",
       "                CCI_5     CCI_10     CCI_21    CCI_50      MOM_5     MOM_10  \\\n",
       "Day                                                                           \n",
       "2015-01-01 -76.487357 -58.930944 -57.963081 -8.626979 -28.059998 -48.588989   \n",
       "2015-01-02 -76.487357 -58.930944 -57.963081 -8.626979 -28.059998 -48.588989   \n",
       "2015-01-03 -76.487357 -58.930944 -57.963081 -8.626979 -28.059998 -48.588989   \n",
       "\n",
       "               MOM_21     RSI_5     RSI_10     RSI_21     RSI_50  \n",
       "Day                                                               \n",
       "2015-01-01 -80.842987  30.94113  30.495281  36.523877  43.526454  \n",
       "2015-01-02 -80.842987  30.94113  30.495281  36.523877  43.526454  \n",
       "2015-01-03 -80.842987  30.94113  30.495281  36.523877  43.526454  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/final_db.csv', index_col=0)\n",
    "df.sort_index(inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model & hyperparameter tuning with Talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get class weights:\n",
    "def cwts(data):\n",
    "    c0, c1 = np.bincount(data['target'])\n",
    "    #making the weights inversely proportional to the amount of observations:\n",
    "    w0, w1 = (1/c0)*(len(data))/2, (1/c1)*(len(data))/2\n",
    "    return {0: w0, 1:w1}\n",
    "\n",
    "# Defining Recall, Precision, Specificity and F1 metrics:\n",
    "#(https://medium.com/analytics-vidhya/custom-metrics-for-keras-tensorflow-ae7036654e05)\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall_keras = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall_keras\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision_keras = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision_keras\n",
    "\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    return tn / (tn + fp + K.epsilon())\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "#========================================================================================#\n",
    "# This function keeps the initial learning rate for the first ten epochs\n",
    "# and decreases it exponentially after that.\n",
    "def scheduler(epoch, lr):\n",
    "    return np.clip(lr * tf.math.exp(-0.1*epoch), 0.000001, 0.001) #limited to these learning rates\n",
    "\n",
    "#========================================================================================#\n",
    "#LSTM ARCHITECTURE\n",
    "def lstm_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    #This function defines the LSTM model\n",
    "    win_length = params['window']\n",
    "    batch_size = params['batch_size']\n",
    "    num_features= x_train.shape[1]\n",
    "    train_generator = TimeseriesGenerator(scaledtrain, y_train, length= win_length, sampling_rate = 1, batch_size= batch_size)\n",
    "    test_generator = TimeseriesGenerator(scaledtest, y_val, length= win_length, sampling_rate = 1, batch_size= batch_size)\n",
    "    #==================================================================#\n",
    "    # MODEL ARCHITECTURE\n",
    "    model = Sequential()\n",
    "    \n",
    "    # #Input and first LSTM layer:\n",
    "    # model.add(LSTM(params['neurons'], activation=params['activation'],input_shape = (win_length, num_features), return_sequences = True))\n",
    "    # model.add(Dropout(params['dropout']))\n",
    "    # # Dropout layer after LSTM layer\n",
    "    # # model.add(Dropout(params['dropout']))\n",
    "\n",
    "    # # Another stacked LSTM layer, to allow for complexity\n",
    "    # model.add(LSTM(params['neurons'], activation=params['activation'],return_sequences=True))\n",
    "    # # Dropout layer after LSTM layer\n",
    "    # model.add(Dropout(params['dropout']))\n",
    "\n",
    "    \n",
    "    # # Third layer to receive all information\n",
    "    # model.add(LSTM(params['neurons'], activation=params['activation'], return_sequences=False))\n",
    "\n",
    "    # # DEnse layer to yield all info to output, reducing dimension\n",
    "    # # if params['activation'] == 'leakyrelu':\n",
    "    # #     model.add(Dense(params['dense_neurons'], activation = tf.keras.layers.LeakyReLU(alpha=0.01)))#output layer\n",
    "    # # else:\n",
    "    # #     model.add(Dense(params['dense_neurons'], activation = params['activation']))#output layer\n",
    "\n",
    "    # model.add(LSTM(128, input_shape = (win_length, num_features), return_sequences = True))\n",
    "    # model.add(LeakyReLU(alpha=0.5))\n",
    "    # model.add(LSTM(128, return_sequences=True))\n",
    "    # model.add(LeakyReLU(alpha=0.5))\n",
    "    # model.add(Dropout(0.3))\n",
    "    # model.add(LSTM(64, return_sequences=False))\n",
    "    # model.add(Dropout(0.3))\n",
    "    # model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Input and first LSTM layer:\n",
    "    model.add(LSTM(params['u1'],input_shape = (win_length, num_features), return_sequences = True))\n",
    "    \n",
    "    # Dropout layer after LSTM layer\n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    # Another stacked LSTM layer, to allow for complexity\n",
    "    model.add(LSTM(params['u2'], return_sequences=True))\n",
    "    # Dropout layer after LSTM layer\n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    \n",
    "    # Third layer to receive all information\n",
    "    model.add(LSTM(params['u3'], return_sequences=False))\n",
    "\n",
    "    # DEnse layer to yield all info to output, reducing dimension\n",
    "    if params['activation'] == 'leakyrelu':\n",
    "        model.add(Dense(params['dense_neurons'], activation = tf.keras.layers.LeakyReLU(alpha=0.01)))#output layer\n",
    "    else:\n",
    "        model.add(Dense(params['dense_neurons'], activation = params['activation']))#output layer\n",
    "    \n",
    "    # Output layer (class =0 or 1)\n",
    "    model.add(Dense(1, activation = 'sigmoid'))#output layer\n",
    "\n",
    "    #==================================================================#\n",
    "    # Defining Early Stopping to avoid overfitting (after 3 attempts)\n",
    "    early_stopping = EarlyStopping(monitor='loss',patience = 5, mode='min', restore_best_weights=True)\n",
    "\n",
    "    # Using exponential decay:\n",
    "    \n",
    "    callbacklr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "    # Compiling\n",
    "    # (lr=lr_normalizer(params['lr'], params['optimizer']))\n",
    "    # callbacks = [early_stopping, callbacklr],\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                    optimizer = params['optimizer'], \n",
    "                    metrics=['accuracy',precision,recall,f1,specificity,])\n",
    "    \n",
    "    history = model.fit(train_generator,\n",
    "                        validation_data=test_generator, # validation sample with features\n",
    "                        epochs = params['epochs'], # validation sample with labels\n",
    "                        shuffle=False, callbacks = [early_stopping, callbacklr],\n",
    "                        class_weight = class_weight, # imbalanced data\n",
    "                        verbose=1\n",
    "                        )\n",
    "\n",
    "    return(history, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate computation we scale the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We scale the data so hasten the LSTM's conversion\n",
    "scaler = MinMaxScaler() \n",
    "\n",
    "\n",
    "# Features x Target\n",
    "\n",
    "features = df.iloc[:,1:]\n",
    "target = df.iloc[:,0]\n",
    "\n",
    "# Shuffle is set to False because it is a timeseries, and the order matters.\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size = 0.20, random_state=0, shuffle = False)\n",
    "\n",
    "# Scaling\n",
    "scaledtrain = scaler.fit_transform(x_train)\n",
    "scaledtest = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the class weights (imbalanced):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.1066666666666667, 1: 0.9120879120879121}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = cwts(df)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/52488 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "45/45 [==============================] - 7s 44ms/step - loss: 0.6945 - accuracy: 0.5247 - precision: 0.3847 - recall: 0.5944 - f1: 0.4466 - specificity: 0.4055 - val_loss: 0.6939 - val_accuracy: 0.4783 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: 0.0000e+00 - val_specificity: 1.0000 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.6928 - accuracy: 0.4434 - precision: 0.1357 - recall: 0.0287 - f1: 0.0449 - specificity: 0.9703 - val_loss: 0.6933 - val_accuracy: 0.4783 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: 0.0000e+00 - val_specificity: 1.0000 - lr: 9.0484e-04\n",
      "Epoch 3/25\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.6923 - accuracy: 0.4468 - precision: 0.2426 - recall: 0.1843 - f1: 0.1722 - specificity: 0.8109 - val_loss: 0.6931 - val_accuracy: 0.5217 - val_precision: 0.5201 - val_recall: 1.0000 - val_f1: 0.6782 - val_specificity: 0.0000e+00 - lr: 7.4082e-04\n",
      "Epoch 4/25\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.6922 - accuracy: 0.4670 - precision: 0.5205 - recall: 0.5030 - f1: 0.4432 - specificity: 0.4735 - val_loss: 0.6931 - val_accuracy: 0.5217 - val_precision: 0.5201 - val_recall: 1.0000 - val_f1: 0.6782 - val_specificity: 0.0000e+00 - lr: 5.4881e-04\n",
      "Epoch 5/25\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.6921 - accuracy: 0.5386 - precision: 0.5595 - recall: 0.8356 - f1: 0.6608 - specificity: 0.1790 - val_loss: 0.6930 - val_accuracy: 0.5217 - val_precision: 0.5201 - val_recall: 1.0000 - val_f1: 0.6782 - val_specificity: 0.0000e+00 - lr: 3.6788e-04\n",
      "Epoch 6/25\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.6921 - accuracy: 0.5497 - precision: 0.5728 - recall: 0.7963 - f1: 0.6546 - specificity: 0.2541 - val_loss: 0.6930 - val_accuracy: 0.5217 - val_precision: 0.5201 - val_recall: 1.0000 - val_f1: 0.6782 - val_specificity: 0.0000e+00 - lr: 2.2313e-04\n",
      "Epoch 7/25\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.6921 - accuracy: 0.5434 - precision: 0.5536 - recall: 0.9291 - f1: 0.6874 - specificity: 0.0640 - val_loss: 0.6930 - val_accuracy: 0.5217 - val_precision: 0.5201 - val_recall: 1.0000 - val_f1: 0.6782 - val_specificity: 0.0000e+00 - lr: 1.2246e-04\n",
      "Epoch 8/25\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.6920 - accuracy: 0.5476 - precision: 0.5541 - recall: 0.9571 - f1: 0.6958 - specificity: 0.0350 - val_loss: 0.6930 - val_accuracy: 0.5217 - val_precision: 0.5201 - val_recall: 1.0000 - val_f1: 0.6782 - val_specificity: 0.0000e+00 - lr: 6.0810e-05\n",
      "Epoch 9/25\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.6921 - accuracy: 0.5532 - precision: 0.5568 - recall: 0.9711 - f1: 0.7017 - specificity: 0.0320 - val_loss: 0.6930 - val_accuracy: 0.5217 - val_precision: 0.5201 - val_recall: 1.0000 - val_f1: 0.6782 - val_specificity: 0.0000e+00 - lr: 2.7324e-05\n",
      "Epoch 10/25\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.6921 - accuracy: 0.5490 - precision: 0.5538 - recall: 0.9639 - f1: 0.6977 - specificity: 0.0292 - val_loss: 0.6930 - val_accuracy: 0.5217 - val_precision: 0.5201 - val_recall: 1.0000 - val_f1: 0.6782 - val_specificity: 0.0000e+00 - lr: 1.1109e-05\n",
      "Epoch 11/25\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.6921 - accuracy: 0.5518 - precision: 0.5553 - recall: 0.9668 - f1: 0.6998 - specificity: 0.0313 - val_loss: 0.6930 - val_accuracy: 0.5217 - val_precision: 0.5201 - val_recall: 1.0000 - val_f1: 0.6782 - val_specificity: 0.0000e+00 - lr: 4.0868e-06\n",
      "Epoch 12/25\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.6920 - accuracy: 0.5566 - precision: 0.5590 - recall: 0.9629 - f1: 0.7015 - specificity: 0.0512 - val_loss: 0.6930 - val_accuracy: 0.5217 - val_precision: 0.5201 - val_recall: 1.0000 - val_f1: 0.6782 - val_specificity: 0.0000e+00 - lr: 1.3604e-06\n",
      "Epoch 13/25\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.6921 - accuracy: 0.5483 - precision: 0.5534 - recall: 0.9619 - f1: 0.6969 - specificity: 0.0290 - val_loss: 0.6930 - val_accuracy: 0.5217 - val_precision: 0.5201 - val_recall: 1.0000 - val_f1: 0.6782 - val_specificity: 0.0000e+00 - lr: 1.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/5832 [26:44<235:51:23, 145.87s/it]\n",
      "  0%|          | 1/52488 [00:18<276:56:03, 18.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "45/45 [==============================] - 6s 50ms/step - loss: 0.6930 - accuracy: 0.5206 - precision: 0.4955 - recall: 0.7359 - f1: 0.5451 - specificity: 0.2614 - val_loss: 0.6920 - val_accuracy: 0.5222 - val_precision: 0.5214 - val_recall: 1.0000 - val_f1: 0.6790 - val_specificity: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.6930 - accuracy: 0.5489 - precision: 0.5540 - recall: 0.9705 - f1: 0.6978 - specificity: 0.0200 - val_loss: 0.6922 - val_accuracy: 0.5222 - val_precision: 0.5214 - val_recall: 1.0000 - val_f1: 0.6790 - val_specificity: 0.0000e+00 - lr: 9.0484e-04\n",
      "Epoch 3/25\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.6924 - accuracy: 0.4922 - precision: 0.4003 - recall: 0.5945 - f1: 0.4427 - specificity: 0.4095 - val_loss: 0.6923 - val_accuracy: 0.5222 - val_precision: 0.5214 - val_recall: 1.0000 - val_f1: 0.6790 - val_specificity: 0.0000e+00 - lr: 7.4082e-04\n",
      "Epoch 4/25\n",
      "31/45 [===================>..........] - ETA: 0s - loss: 0.6880 - accuracy: 0.5746 - precision: 0.5734 - recall: 1.0000 - f1: 0.7226 - specificity: 0.0032"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\enzoy\\Desktop\\CQF_final_project\\DL.ipynb Célula: 13\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m1e-2\u001b[39m, \u001b[39m1e-3\u001b[39m, \u001b[39m1e-4\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mu1\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m32\u001b[39m,\u001b[39m64\u001b[39m,\u001b[39m128\u001b[39m], \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mu2\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m32\u001b[39m,\u001b[39m64\u001b[39m,\u001b[39m128\u001b[39m], \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mwindow\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m21\u001b[39m,\u001b[39m50\u001b[39m,\u001b[39m200\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Scanning for best hyperparameters with Talos\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m scan \u001b[39m=\u001b[39m talos\u001b[39m.\u001b[39;49mScan(x \u001b[39m=\u001b[39;49m x_train, y \u001b[39m=\u001b[39;49m y_train, x_val \u001b[39m=\u001b[39;49m x_test, y_val \u001b[39m=\u001b[39;49m y_test, params \u001b[39m=\u001b[39;49m params, model \u001b[39m=\u001b[39;49m lstm_model,experiment_name \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mlstm_model_val\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\talos\\scan\\Scan.py:205\u001b[0m, in \u001b[0;36mScan.__init__\u001b[1;34m(self, x, y, params, model, experiment_name, x_val, y_val, val_split, multi_input, random_method, seed, performance_target, fraction_limit, round_limit, time_limit, boolean_limit, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, minimize_loss, disable_progress_bar, print_params, clear_session, save_weights, save_models)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39m# start runtime\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mscan_run\u001b[39;00m \u001b[39mimport\u001b[39;00m scan_run\n\u001b[1;32m--> 205\u001b[0m scan_run(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\talos\\scan\\scan_run.py:26\u001b[0m, in \u001b[0;36mscan_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[39m# otherwise proceed with next permutation\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mscan_round\u001b[39;00m \u001b[39mimport\u001b[39;00m scan_round\n\u001b[1;32m---> 26\u001b[0m     \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m scan_round(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m     27\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[39m# close progress bar before finishing\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\talos\\scan\\scan_round.py:19\u001b[0m, in \u001b[0;36mscan_round\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# fit the model\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mingest_model\u001b[39;00m \u001b[39mimport\u001b[39;00m ingest_model\n\u001b[1;32m---> 19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_history, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mround_model \u001b[39m=\u001b[39m ingest_model(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m     20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mround_history\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_history\u001b[39m.\u001b[39mhistory)\n\u001b[0;32m     22\u001b[0m \u001b[39m# handle logging of results\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\talos\\model\\ingest_model.py:6\u001b[0m, in \u001b[0;36mingest_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mingest_model\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[39m'''Ingests the model that is input by the user\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m    through Scan() model paramater.'''\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_train,\n\u001b[0;32m      7\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_train,\n\u001b[0;32m      8\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_val,\n\u001b[0;32m      9\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_val,\n\u001b[0;32m     10\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mround_params)\n",
      "\u001b[1;32mc:\\Users\\enzoy\\Desktop\\CQF_final_project\\DL.ipynb Célula: 13\u001b[0m in \u001b[0;36mlstm_model\u001b[1;34m(x_train, y_train, x_val, y_val, params)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m \u001b[39m# Compiling\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m \u001b[39m# (lr=lr_normalizer(params['lr'], params['optimizer']))\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m \u001b[39m# callbacks = [early_stopping, callbacklr],\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m                 optimizer \u001b[39m=\u001b[39m params[\u001b[39m'\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m                 metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m,precision,recall,f1,specificity,])\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mtest_generator, \u001b[39m# validation sample with features\u001b[39;49;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m                     epochs \u001b[39m=\u001b[39;49m params[\u001b[39m'\u001b[39;49m\u001b[39mepochs\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m# validation sample with labels\u001b[39;49;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m                     shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, callbacks \u001b[39m=\u001b[39;49m [early_stopping, callbacklr],\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m                     class_weight \u001b[39m=\u001b[39;49m class_weight, \u001b[39m# imbalanced data\u001b[39;49;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m                     )\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/enzoy/Desktop/CQF_final_project/DL.ipynb#X25sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m \u001b[39mreturn\u001b[39;00m(history, model)\n",
      "File \u001b[1;32mc:\\Users\\enzoy\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\enzoy\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Defining parameters considered in the hyperparameter tuning\n",
    "params = {'lr': [1e-2, 1e-3, 1e-4],\n",
    "        'u1': [64,128, 256], \n",
    "        'u2': [64,128, 256], \n",
    "        'u3': [64,128, 256], \n",
    "        'dropout': [0.3, 0.5, 0.8],\n",
    "        'batch_size': [32, 64, 256], \n",
    "        'epochs': [25,50],\n",
    "        'optimizer': ['Adam','Nadam'],\n",
    "        'activation': ['leakyrelu','relu'],\n",
    "        'dense_neurons': [8, 32, 64],\n",
    "        'window': [21,50,200],\n",
    "        }\n",
    "\n",
    "# Scanning for best hyperparameters with Talos\n",
    "scan = talos.Scan(x = x_train, y = y_train, x_val = x_test, y_val = y_test, params = params, model = lstm_model,experiment_name = 'lstm_model_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4a7f35d67f0eebd5d6cc2f40fad7bfa5c560608ca95bf5c0b59e3274634f582"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
