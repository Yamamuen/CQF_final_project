{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Classifier\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Dropout, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import talos\n",
    "from talos.utils import lr_normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import metrics\n",
    "import keras.backend as K\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking whether tensorflow is running on GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing final dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>mean_sent</th>\n",
       "      <th>STOCH_slowk</th>\n",
       "      <th>STOCH_slowd</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_hist</th>\n",
       "      <th>CCI_5</th>\n",
       "      <th>CCI_10</th>\n",
       "      <th>CCI_21</th>\n",
       "      <th>CCI_50</th>\n",
       "      <th>MOM_5</th>\n",
       "      <th>MOM_10</th>\n",
       "      <th>MOM_21</th>\n",
       "      <th>RSI_5</th>\n",
       "      <th>RSI_10</th>\n",
       "      <th>RSI_21</th>\n",
       "      <th>RSI_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011820</td>\n",
       "      <td>67.198744</td>\n",
       "      <td>57.422805</td>\n",
       "      <td>-12.540186</td>\n",
       "      <td>4.426599</td>\n",
       "      <td>-76.487357</td>\n",
       "      <td>-58.930944</td>\n",
       "      <td>-57.963081</td>\n",
       "      <td>-8.626979</td>\n",
       "      <td>-28.059998</td>\n",
       "      <td>-48.588989</td>\n",
       "      <td>-80.842987</td>\n",
       "      <td>30.94113</td>\n",
       "      <td>30.495281</td>\n",
       "      <td>36.523877</td>\n",
       "      <td>43.526454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>67.198744</td>\n",
       "      <td>57.422805</td>\n",
       "      <td>-12.540186</td>\n",
       "      <td>4.426599</td>\n",
       "      <td>-76.487357</td>\n",
       "      <td>-58.930944</td>\n",
       "      <td>-57.963081</td>\n",
       "      <td>-8.626979</td>\n",
       "      <td>-28.059998</td>\n",
       "      <td>-48.588989</td>\n",
       "      <td>-80.842987</td>\n",
       "      <td>30.94113</td>\n",
       "      <td>30.495281</td>\n",
       "      <td>36.523877</td>\n",
       "      <td>43.526454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009646</td>\n",
       "      <td>67.198744</td>\n",
       "      <td>57.422805</td>\n",
       "      <td>-12.540186</td>\n",
       "      <td>4.426599</td>\n",
       "      <td>-76.487357</td>\n",
       "      <td>-58.930944</td>\n",
       "      <td>-57.963081</td>\n",
       "      <td>-8.626979</td>\n",
       "      <td>-28.059998</td>\n",
       "      <td>-48.588989</td>\n",
       "      <td>-80.842987</td>\n",
       "      <td>30.94113</td>\n",
       "      <td>30.495281</td>\n",
       "      <td>36.523877</td>\n",
       "      <td>43.526454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  mean_sent  STOCH_slowk  STOCH_slowd       MACD  MACD_hist  \\\n",
       "Day                                                                             \n",
       "2015-01-01     0.0   0.011820    67.198744    57.422805 -12.540186   4.426599   \n",
       "2015-01-02     1.0   0.009464    67.198744    57.422805 -12.540186   4.426599   \n",
       "2015-01-03     0.0   0.009646    67.198744    57.422805 -12.540186   4.426599   \n",
       "\n",
       "                CCI_5     CCI_10     CCI_21    CCI_50      MOM_5     MOM_10  \\\n",
       "Day                                                                           \n",
       "2015-01-01 -76.487357 -58.930944 -57.963081 -8.626979 -28.059998 -48.588989   \n",
       "2015-01-02 -76.487357 -58.930944 -57.963081 -8.626979 -28.059998 -48.588989   \n",
       "2015-01-03 -76.487357 -58.930944 -57.963081 -8.626979 -28.059998 -48.588989   \n",
       "\n",
       "               MOM_21     RSI_5     RSI_10     RSI_21     RSI_50  \n",
       "Day                                                               \n",
       "2015-01-01 -80.842987  30.94113  30.495281  36.523877  43.526454  \n",
       "2015-01-02 -80.842987  30.94113  30.495281  36.523877  43.526454  \n",
       "2015-01-03 -80.842987  30.94113  30.495281  36.523877  43.526454  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/final_db.csv', index_col=0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model & hyperparameter tuning with Talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get class weights:\n",
    "def cwts(data):\n",
    "    c0, c1 = np.bincount(data['target'])\n",
    "    #making the weights inversely proportional to the amount of observations:\n",
    "    w0, w1 = (1/c0)*(len(data))/2, (1/c1)*(len(data))/2\n",
    "    return {0: w0, 1:w1}\n",
    "\n",
    "# Defining Recall, Precision, Specificity and F1 metrics:\n",
    "#(https://medium.com/analytics-vidhya/custom-metrics-for-keras-tensorflow-ae7036654e05)\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall_keras = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall_keras\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision_keras = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision_keras\n",
    "\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    return tn / (tn + fp + K.epsilon())\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "#========================================================================================#\n",
    "# This function keeps the initial learning rate for the first ten epochs\n",
    "# and decreases it exponentially after that.\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < 10:\n",
    "    return lr\n",
    "  else:\n",
    "    return np.clip(lr * tf.math.exp(-0.1), 0.000001, 0.001) #limited to these learning rates\n",
    "\n",
    "#========================================================================================#\n",
    "#LSTM ARCHITECTURE\n",
    "def lstm_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    #This function defines the LSTM model\n",
    "    win_length = params['window']\n",
    "    batch_size = params['batch_size']\n",
    "    num_features= x_train.shape[1]\n",
    "    train_generator = TimeseriesGenerator(x_train, y_train, length= win_length, sampling_rate = 1, batch_size= batch_size)\n",
    "    test_generator = TimeseriesGenerator(x_val, y_val, length= win_length, sampling_rate = 1, batch_size= batch_size)\n",
    "    #==================================================================#\n",
    "    # MODEL ARCHITECTURE\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Input and first LSTM layer:\n",
    "    model.add(LSTM(params['neurons'],input_shape = (win_length, num_features), return_sequences = True))\n",
    "    \n",
    "    # Dropout layer after LSTM layer\n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    # Another stacked LSTM layer, to allow for complexity\n",
    "    model.add(LSTM(params['neurons'], return_sequences=True))\n",
    "    # Dropout layer after LSTM layer\n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    \n",
    "    # Third layer to receive all information\n",
    "    model.add(LSTM(params['neurons'], return_sequences=False))\n",
    "\n",
    "    # DEnse layer to yield all info to output, reducing dimension\n",
    "    if params['activation'] == 'leakyrelu':\n",
    "        model.add(Dense(params['dense_neurons'], activation = tf.keras.layers.LeakyReLU(alpha=0.01)))#output layer\n",
    "    else:\n",
    "        model.add(Dense(params['dense_neurons'], activation = params['activation']))#output layer\n",
    "\n",
    "    \n",
    "    # Output layer (class =0 or 1)\n",
    "    model.add(Dense(1, activation = 'sigmoid'))#output layer\n",
    "    \n",
    "    #==================================================================#\n",
    "    # Defining Early Stopping to avoid overfitting (after 3 attempts)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss',patience = 3, mode='min')\n",
    "\n",
    "    # Using exponential decay:\n",
    "    \n",
    "    callbacklr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "    # Compiling\n",
    "    # (lr=lr_normalizer(params['lr'], params['optimizer']))\n",
    "    # callbacks = [early_stopping, callbacklr],\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                    optimizer = params['optimizer'], \n",
    "                    metrics=['accuracy',precision,recall,f1,specificity,])\n",
    "    \n",
    "    history = model.fit(train_generator,\n",
    "                        validation_data=test_generator, # validation sample with features\n",
    "                        epochs = params['epochs'], # validation sample with labels\n",
    "                        shuffle=False, callbacks = [early_stopping, callbacklr],\n",
    "                        class_weight = class_weight, # imbalanced data\n",
    "                        verbose=2\n",
    "                        )\n",
    "\n",
    "    return(history, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate computation we scale the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We scale the data so hasten the LSTM's conversion\n",
    "scaler = MinMaxScaler() \n",
    "\n",
    "dffinal_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Features x Target\n",
    "features = dffinal_scaled\n",
    "target = dffinal_scaled[:,0]\n",
    "\n",
    "# Shuffle is set to False because it is a timeseries, and the order matters.\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size = 0.20, random_state=0, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the class weights (imbalanced):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.1066666666666667, 1: 0.9120879120879121}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = cwts(df)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "182/182 - 9s - loss: 0.6925 - accuracy: 0.5230 - precision: 0.3807 - recall: 0.6735 - f1: 0.4763 - specificity: 0.3204 - val_loss: 0.6925 - val_accuracy: 0.5208 - val_precision: 0.5109 - val_recall: 0.9783 - val_f1: 0.6577 - val_specificity: 0.0000e+00 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 2/25\n",
      "182/182 - 3s - loss: 0.6923 - accuracy: 0.5010 - precision: 0.3056 - recall: 0.5158 - f1: 0.3709 - specificity: 0.4834 - val_loss: 0.6935 - val_accuracy: 0.4792 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: 0.0000e+00 - val_specificity: 1.0000 - lr: 0.0010 - 3s/epoch - 19ms/step\n",
      "Epoch 3/25\n",
      "182/182 - 3s - loss: 0.6914 - accuracy: 0.5168 - precision: 0.3431 - recall: 0.5402 - f1: 0.4014 - specificity: 0.4472 - val_loss: 0.6933 - val_accuracy: 0.4986 - val_precision: 0.0960 - val_recall: 0.0732 - val_f1: 0.0776 - val_specificity: 0.9377 - lr: 0.0010 - 3s/epoch - 19ms/step\n",
      "Epoch 4/25\n"
     ]
    }
   ],
   "source": [
    "# Defining parameters considered in the hyperparameter tuning\n",
    "params = {'lr': [0.01, 0.001],\n",
    "        'neurons': [32, 64, 128], \n",
    "        'dropout': [0, 0.3, 0.5],\n",
    "        'batch_size': [8, 32, 64, 128, 512], \n",
    "        'epochs': [25, 50],\n",
    "        'optimizer': ['Nadam', 'Adam','SGD'],\n",
    "        'activation': ['leakyrelu','relu','elu'],\n",
    "        'dense_neurons': [8, 16, 32],\n",
    "        'window': [5,10,21,50],\n",
    "        }\n",
    "\n",
    "# Scanning for best hyperparameters with Talos\n",
    "scan = talos.Scan(x = x_train, y = y_train, x_val = x_test, y_val = y_test, params = params, model = lstm_model,experiment_name = 'lstm_model_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4a7f35d67f0eebd5d6cc2f40fad7bfa5c560608ca95bf5c0b59e3274634f582"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
